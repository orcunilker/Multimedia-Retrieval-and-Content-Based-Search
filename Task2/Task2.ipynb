{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Movie recognition (40 Pt.)\n",
    "Assign each video clip from the test set to a movie from the development set. Consider the following workflow: <br><img src=\"imgs/VideoClassificationWorkflow.png\" alt=\"Movie recognition workflow: Step 1: shot cut detection, Step 2: Keyframe extraction, Step 3: Feature extraction, Step 4: Feature comparision\" style=\"vertical-align:text-bottom; margin: 0 .5em;\">&nbsp; <br>\n",
    "\n",
    "<ol>\n",
    "<li><b>Shot Cut Detection:</b><br>choose your best performing approach from Task 1.</li>\n",
    "<li><b>Keyframe Extraction:</b><br>as keyframe representation for each shot select the midframe of the shot.</li>\n",
    "<li><b>Feature Extraction:</b><br>implement two image features that you consider meaningful as feature representation for each keyframe (e.g. color histogram, dominant color, edge histogram, â€¦). (Bonus: MPEG-7 features)</li>\n",
    "<li><b>Feature Comparison:</b><br>you can represent each clip as the mean of all representing features or you can try to classify each keyframe separately and use some rules to label the original video sequence. Implement the approach you consider more meaningful.</li>\n",
    "</ol>\n",
    "\n",
    "<p>Run your implementation with each of the videos of the test set as input.&nbsp; For each\n",
    "input clip compute the most similar clip from the development set and check if\n",
    "the clips are from the same movie. Using the video name of the test set as\n",
    "ground truth compute recall, precision and F1 measures for both implemented\n",
    "features separately. <br>\n",
    "Tip: Extract the features for each video clip once using OpenCV and keep them in a separate Notebook cell.\n",
    "For the feature comparison use these pre-computed features for the requested\n",
    "videos. </p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Implementation.ipynb\n",
    "\n",
    "find_closest_in_devset(show_keyframes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>(see&nbsp; <span lang=\"EN-GB\"><a href=\"https://opencv24-python-tutorials.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_table_of_contents_imgproc/py_table_of_contents_imgproc.html\"><span lang=\"EN-US\">https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_table_of_contents_imgproc/py_table_of_contents_imgproc.html</span></a></span>)</p><p>Thus, you do\n",
    "not have to re-compute the features for each input video (which can take some\n",
    "time depending on the features and implementation). </p>\n",
    "\n",
    "\n",
    "### Answer the following questions:\n",
    "\n",
    "##### Why did you choose these features?\n",
    "...\n",
    "##### Describe the approach that you applied for Step 4.\n",
    "...\n",
    "##### Provide a figure/table of recall, precision and F1 measure for both features and discuss the results.\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
