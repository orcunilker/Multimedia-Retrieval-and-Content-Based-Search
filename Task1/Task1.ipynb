{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Task 1 - Preprocessing, signal manipulation (20 pts)</h2><p>In order to\n",
    "use the given video files for calculation and analysis of the audio track, the\n",
    "files have to be preprocessed for efficiency, performance, and system resource\n",
    "reasons. The following transformation steps have to be performed. The given\n",
    "figure illustrates how to work them off.</p>\n",
    "\n",
    "<ul>\n",
    " <li>Extraction and Decoding of the\n",
    "     AAC-encoded audio track out of the MPEG-4 video files</li>\n",
    " <ul>\n",
    "  <li>You can easily achieve this\n",
    "      using FFMPEG and the following command:&nbsp;</li>\n",
    "  <li>ffmpeg\n",
    "      -i &lt;input_file.mp4&gt; -acodec pcm_s16le -y &lt;output_file.wav&gt;</li>\n",
    "   <li>Use Python subprocesses to make such an FFMPEG call.</li>\n",
    " </ul>\n",
    " <li>Resampling (reduction of sampling\n",
    "     frequency down to 22050/11025/8000 Hz).</li>\n",
    " <li>Normalization of the audio\n",
    "     files</li>\n",
    " <li>Downmix all included channels\n",
    "     down to one (--&gt; mono signal)</li>\n",
    "</ul>\n",
    "\n",
    "<p>Using scipy\n",
    "or LibROSA &nbsp;in <b>Python</b>, you can\n",
    "easily read PCM-encoded WAV-files. Check,</p>\n",
    "\n",
    "<p><span lang=\"EN-GB\"><a href=\"https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.io.wavfile.read.html\"><span lang=\"EN-US\">https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.io.wavfile.read.html</span></a></span></p>\n",
    "\n",
    "<p><span lang=\"EN-GB\"><a href=\"https://librosa.github.io/librosa/tutorial.html\"><span lang=\"EN-US\">https://librosa.github.io/librosa/tutorial.html</span></a></span></p>\n",
    "\n",
    "<p>Your samples\n",
    "can then be further processed as they are stored in a numpy array.</p><br><p><img src=\"imgs/preprocess.png\" alt=\"Preprocessing Steps\" width=\"200\" height=\"270\"></p><p>For these\n",
    "transformation steps (<b>except</b> audio track extraction and decoding),\n",
    "provide a <b>Jupyter Notebook</b> that combines all the necessary steps. Prepare a plot to be shown in the below call, using <b>matplotlib</b>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import your solution here\n",
    "%run Implementation.ipynb\n",
    "\n",
    "target_sr = 22050\n",
    "y = preprocess(input_file = \"../videos/DevSet/01_DevilsAdvocate_02.mp4\", output_file = \"../testfile_processed.wav\", target_sr = target_sr)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "librosa.display.waveshow(y, sr=target_sr)\n",
    "plt.title('Processed Audiofile')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do also consider a function to preprocess all audio files within a directory, so that you can conveniently sample all provided video files at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Implementation.ipynb\n",
    "\n",
    "preprocessDirectory(input_directory = \"../videos/DevSet\", output_directory = \"../videos/processed\", target_sr = 22050)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Questions\n",
    "Critically think about the following questions and answer them below</p>\n",
    "\n",
    "\n",
    " #### 1. What is the objective of each step and why are they necessary or needless?\n",
    "   - Extracting Audio from Video\n",
    "      - We have to do this to be able to process the audio, as it is embedded in the MPEG-4 file\n",
    "   - Decoding from AAC to WAV\n",
    "      - We cant work with AAC, as it is a complex encoded Format\n",
    "      - WAV is relatively simple, containing the PCM Signal and it's properties\n",
    "      - it can be treated like a vector\n",
    "   - Resampling\n",
    "      - It is not a mandatory step, but if we resample the audio to a lower sample-rate, there is less data to work with\n",
    "      - It helps gaining performance\n",
    "   - Amplitude Normalization\n",
    "      - This is also not mandatory, but this is the best way to bring the audio signal to the highest level without losing information\n",
    "      - Making it more comparable to other audio files\n",
    "   - Downmix to Mono\n",
    "      - This is somewhat mandatory, as we want to have just one signal to work with\n",
    "      - We don't need the stereo information for our needs\n",
    "       \n",
    "\n",
    " #### 2. What is the impact of the chosen sampling frequency with regard to further processing steps?\n",
    "   - Once resampled to a lower sampling frequency, one isn't able to bring the lost information back\n",
    "   - Recovering the lost information isn't possible anymore\n",
    "   - Important information (in high frequencies) might got lost\n",
    "\n",
    " #### 3. Think about feasible strategies, alternative procedures, and their consequences. What could be common pitfalls?\n",
    " ...\n",
    "\n",
    " #### 4. What are the consequences for the resulting audio files with respect to the extractable information before and after the processes?\n",
    " *Provide two figures (for one exemplary file only) which demonstrates the effects on the signal before and after the transformation. Choose proper axis ranges in order to make the changes clearly apparent.*\n",
    " \n",
    " ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Implementation.ipynb\n",
    "input = \"../videos/DevSet/01_PulpFiction_02.mp4\"\n",
    "output = \"test.wav\"\n",
    "subprocess.run(['ffmpeg', '-i', input, '-acodec' ,'pcm_s16le', '-y', output])\n",
    "\n",
    "y_original, orig_sr = librosa.load(\"test.wav\", sr=None, mono=False)\n",
    "\n",
    "target_sr\n",
    "y_preprocessed = preprocess(input_file = input, output_file = \"test_processed.wav\", target_sr = target_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "librosa.display.waveshow(y_original, sr=orig_sr)\n",
    "plt.title('Original Audiofile')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.ylim([-1, 1]) \n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "librosa.display.waveshow(y_preprocessed, sr=target_sr)\n",
    "plt.title('Preprocessed Audiofile')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.ylim([-1, 1]) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You should turn in: ### \n",
    "* Answers to the given questions\n",
    "* 2 figures\n",
    "* jupyter notebook (Implementation) that performs the preprocessing steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
